[{"id":0,"href":"/documentation/Diagrams/Architecture-Diagram/","title":"Architecture Diagram","parent":"Diagrams","content":"The data relative to the number of people detected by Wi-Fi sniffing and object detection and the number of moliceiros detected by object detection is captured by the respective modules in the sensors and this data is sent to the broker through a MQTT connection. The broker saves the data in a database and also sends it to the Web service (Flask). The web server (Gunicorn) interacts with the Web service and communicates with the Reverse Proxy Server (Nginx) through a Unix socket. The Reverse Proxy Server manages the load balance of requests. The user visualizes the web application in his device, sending and receiving HTTPS requests and responses.\n "},{"id":1,"href":"/documentation/Diagrams/Deployment-Diagram/","title":"Deployment Diagram","parent":"Diagrams","content":"In this diagram it is possible to view the several components of the system and how they interact between them.\n "},{"id":2,"href":"/documentation/Diagrams/Domain-Diagram/","title":"Domain Diagram","parent":"Diagrams","content":"The domain model of the project represents the real-world conceptual classes of the system, their attributes and how they are associated.\n "},{"id":3,"href":"/documentation/Diagrams/Use-Cases-Diagrams/","title":"Use Cases Diagrams","parent":"Diagrams","content":"API     Web Application     "},{"id":4,"href":"/documentation/Modules/Server-Configuration/","title":"Server Configuration","parent":"Modules","content":"The following topics describe the server configuration following the work flow to do so:\n The WebAppDev repository was cloned to the virtual machine  Gunicorn     A service of gunicorn was created to run the web application using eventlet on the same address and port of socket instanced on the web application. The file is located in /etc/systemd/system/webapp.service  [Unit] Description=Gunicorn instance to serve PEI2021_NAP project After=network.target [Service] User=hugolardosa Group=www-data WorkingDirectory=path/WebAppDev Environment=\u0026quot;PATH=path/WebAppDev/avenv/bin\u0026quot; ExecStart=path/WebAppDev/avenv/bin/gunicorn --worker-class eventlet -w 1 --bind=\u0026quot;0.0.0.0:5000\u0026quot; app:app [Install] WantedBy=multi-user.target It\u0026rsquo;s important to mention the gunicorn run atributes (gunicorn \u0026ndash;worker-class eventlet -w 1 \u0026ndash;bind=\u0026ldquo;0.0.0.0:5000\u0026rdquo; app:app)\n \u0026ndash;worker-class eventlet -w 1 These attributes are used to run the web server using the asynchronous process for socket.io \u0026ndash;bind=\u0026ldquo;0.0.0.0:5000\u0026rdquo; Indicates gunicorn the address and port the app and socket is running, NEEDS TO BE THE SAME AS THE ONE IN THE NGINX CONFIGURATION FILE app:app Indicates gunicorn the name and attribute of the flask web application  We need to run the webapp service, so it will always be running using sudo systemctl start webapp\nNGINX    We then need to configure the NGINX reverse proxy server, we need to link the local gunicorn and redirect it to the dev.aveiro-open-lab.pt.\n The file is located in /etc/nginx/sites-available/webapp  We start the file by pointing the / in the server to the local web app (0:0:0:0:5000)\nserver{ server_name dev.aveiro-open-lab.pt; location / { include proxy_params; proxy_pass http://0.0.0.0:5000; } Then, we need to point the /socket.io on the server to the local socket 0.0.0.0:5000 one\n location /socket.io{ include proxy_params; proxy_http_version 1.1; proxy_buffering off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026quot;Upgrade\u0026quot;; proxy_pass http://0.0.0.0:5000/socket.io; } The rest of the file was generated by certbot so we can have the webapp running on https\n listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/dev.aveiro-open-lab.pt/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/dev.aveiro-open-lab.pt/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } server{ if ($host = dev.aveiro-open-lab.pt) { return 301 https://$host$request_uri; } # managed by Certbot listen 80; server_name dev.aveiro-open-lab.pt; return 404; # managed by Certbot } We need to run the nginx service, so it will always be running using sudo systemctl start nginx\n"},{"id":5,"href":"/documentation/Modules/Sniffing/","title":"Sniffing","parent":"Modules","content":"Context    The sniffing module is written in Python3 and runs as a service on the Smart Lamp Post APU. It is responsible for capturing probe requests packets and send to a broker values about current devices as well as unique devices that have passed by the post, in real-time.\nDescription    The module uses PyShark which is a wrapper for TShark (TShark is a terminal based version of wireshark). In order to capture WiFi packets, we turned on monitor mode on wlan1 interface of the APU\u0026rsquo;s wireless network adapter. The PyShark\u0026rsquo;s capture filter is set to probe requests, which are packets that are sent by a device scanning for access points in the area and are sent periodically. From these packets we are able to extract each device\u0026rsquo;s mac address and use it for our statistics purpose.\nHow to configure the lamp post APU wlan1 interface into monitor mode    ifconfig wlan1 down iwconfig wlan1 mode monitor ifconfig wlan1 up Threads    In this file there are 2 running threads and 1 main function running permanently: chopping() thread, run_broker() thread and the main function where the PyShark is capturing the packets. The first thread, chopping, is responsible for constantly switching wifi channels through 1, 6 and 11. The broker thread implements the producer-side of the broker where the messages are sent and are later consumed by the web app.\nfor channel in channels: os.system(\u0026#34;iwconfig \u0026#34; + monitor_iface + \u0026#34; channel \u0026#34; + str(channel) + \u0026#34; \u0026gt; /dev/null 2\u0026gt;\u0026amp;1\u0026#34;)\tThe second thread, run_broker, is responsible for sending the sniffing data to the broker\ndef main(): #Chopper Thread chopper = threading.Thread(target=chopping) chopper.daemon = True chopper.start() #Broker Thread brokerthread = threading.Thread(target=run_broker) brokerthread.daemon = True brokerthread.start() #(...) Packet Handling    As probe request packets are being captured by PyShark, they are processed by a function, packetHandler(), which filters packets that only are sent by client devices searching for access points in broadcast. Therefore, all AP\u0026rsquo;s sending beacon frames advertising their SSID as well as devices already connected to a certain SSID/access point are all dropped. After this process, the function retrieves the mac address from the packet and records the current time. This pair of values are saved this in a dictionary and represent the current list of in range devices. Afterward, the same mac address is introduced into the unique devices set, in order to prevent repetitions of the same mac address. In the end of every iteration of this function, another function is called: peopleUpdate() which goes through the dictionary of the current devices and checks the difference between the current time and the time when each mac address was captured and if the difference is greater than 5 seconds that pair of value stored in the dictionary is removed.\nBroker    The broker connects to the IP address and a port of the broker installed on the Jetson\u0026rsquo;s post and publishes messages on 2 different topics: \u0026ldquo;sniffing/current\u0026rdquo; and \u0026ldquo;sniffing/unique\u0026rdquo;. The first topic is where the current number of devices is published every 5 seconds while the second topic contains the number of unique devices, sent every 60 seconds.\n"},{"id":6,"href":"/documentation/Modules/WebApp/","title":"Web App","parent":"Modules","content":"Basic architecture of the web application    The web application is a flask app, running on the gunicorn server and uses NGINX has a proxy server.\nFile Structure     app.py - main app running on server /templates - folder containing all the Static rendered Jinja2 HTML files /templates/template.html - contains the base HTML page /templates/index.html - extends template and has the HTML code to homepage elements /templates/person.html - extends template and has the HTML code to show the detection data  Main functions    The two main functions of the app are home() and people():\n home() - renders the template of the index HTML webpage. people() - renders the template of the main page where the detection data is showed.  To render the HTML pages with jinja the functions return render_template(\u0026lsquo;person.html\u0026rsquo;, pagename=\u0026ldquo;Moliceiros and People detection\u0026rdquo;) the argument pagename renders the page name on the html files\nBroker access    In flask we access the broker and subscribe to topics to get real time data. On these lines of code we access the broker\napp.config[\u0026#39;MQTT_BROKER_URL\u0026#39;] = \u0026#39;###.nap.av.it.pt\u0026#39; app.config[\u0026#39;MQTT_BROKER_PORT\u0026#39;] = 1883 app.config[\u0026#39;MQTT_REFRESH_TIME\u0026#39;] = 1.0 mqtt = Mqtt(app) mqtt = Mqtt(app) starts the broker access for the Broker. handle_connect subscribes to the topic, and handle_mqtt_message, gets the message in real-time and sends it through a socket to the web app\n@mqtt.on_connect() def handle_connect(client, userdata, flags, rc): mqtt.subscribe(\u0026#39;sniffing\u0026#39;) @mqtt.on_message() def handle_mqtt_message(client, userdata, message): data = dict( topic=message.topic, payload=message.payload.decode() ) # emit a mqtt_message event to the socket containing the message data socketio.emit(\u0026#39;mqtt_message\u0026#39;, data=data) print(data) Socket IO    To show in real time the broker data from flask to HTML, we need to open a socket using socket.io, for that in the app.py file we: create a variable named socketio = SocketIO(app), and when receiving a message from the broker we send the data to the socket socketio.emit(\u0026lsquo;mqtt_message\u0026rsquo;, data=data)\nOn the html - template page:\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;//cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; charset=\u0026#34;utf-8\u0026#34;\u0026gt; $(document).ready(function() { var socket = io(); socket.on(\u0026#39;connect\u0026#39;, function() { socket.emit(\u0026#39;my event\u0026#39;, {data: \u0026#39;I\\\u0026#39;m connected!\u0026#39;}); }); // listen for mqtt_message events  // when a new message is received, log and append the data to the page  socket.on(\u0026#39;mqtt_message\u0026#39;, (data) =\u0026gt; { console.log(data); $(\u0026#39;#sniffing_div\u0026#39;).html(data[\u0026#39;payload\u0026#39;]); //replace sniffing div  }) }); \u0026lt;/script\u0026gt; We connect to the socket and then send the data to the corresponded div\n"},{"id":7,"href":"/documentation/Tools/DeepStream-SDK-Installation/","title":"Deep Stream Sdk Installation","parent":"Tools","content":"NVIDIA® DeepStream Software Development Kit (SDK) is an accelerated AI framework to build intelligent video analytics (IVA) pipelines.\nThe following section describes how to install DeepStream SDK on the Jetson Nano. All steps are also available here.\n Note: The version 5.1 of the DeepStream SDK is only compatible with JetPack 4.5.1.\n Install Jetson SDK components    Download NVIDIA SDK Manager from https://developer.nvidia.com/embedded/jetpack. You will use this to install JetPack 4.5.1 GA (corresponding to L4T 32.5.1 release). This comes packaged with CUDA, TensorRT and cuDNN.\nInstall Dependencies    Enter the following commands to install the prerequisite packages:\n$ sudo apt install \\ libssl1.0.0 \\ libgstreamer1.0-0 \\ gstreamer1.0-tools \\ gstreamer1.0-plugins-good \\ gstreamer1.0-plugins-bad \\ gstreamer1.0-plugins-ugly \\ gstreamer1.0-libav \\ libgstrtspserver-1.0-0 \\ libjansson4=2.11-1 Install librdkafka (to enable Kafka protocol adaptor for message broker)     Clone the librdkafka repository from GitHub: $ git clone https://github.com/edenhill/librdkafka.git  Configure and build the library: $ cd librdkafka $ git reset --hard 7101c2310341ab3f4675fc565f64f0967e135a6a $ ./configure $ make $ sudo make install  Copy the generated libraries to the deepstream directory: $ sudo mkdir -p /opt/nvidia/deepstream/deepstream-5.1/lib $ sudo cp /usr/local/lib/librdkafka* /opt/nvidia/deepstream/deepstream-5.1/lib   Install the DeepStream SDK    Method 1: Using SDK Manager    Select DeepStreamSDK from the Additional SDKs section along with JP 4.5.1 software components for installation.\nMethod 2: Using the DeepStream tar package (method used by the group)      Download the DeepStream 5.1 Jetson tar package deepstream_sdk_v5.1.0_jetson.tbz2, to the Jetson device.\n  Enter the following commands to extract and install the DeepStream SDK:\n$ sudo tar -xvf deepstream_sdk_v5.1.0_jetson.tbz2 -C / $ cd /opt/nvidia/deepstream/deepstream-5.1 $ sudo ./install.sh $ sudo ldconfig   Method 3: Using the DeepStream Debian package    Download the DeepStream 5.1 Jetson Debian package deepstream-5.1_5.1.0-1_arm64.deb, to the Jetson device. Then enter the command:\n$ sudo apt-get install ./deepstream-5.1_5.1.0-1_arm64.deb  Note: If you install the DeepStream SDK Debian package using the dpkg command, you must install the following packages before installing the debian package: libgstrtspserver-1.0-0 libgstreamer-plugins-base1.0-dev\n Method 4:Using the apt-server      Open the apt source configuration file in a text editor, using a command similar to\n$ sudo vi /etc/apt/sources.list.d/nvidia-l4t-apt-source.list   Change the repository name and download URL in the deb commands shown below:\ndeb https://repo.download.nvidia.com/jetson/common r32.5 main   Save and close the source configuration file.\n  Enter the commands:\n$ sudo apt update $ sudo apt install deepstream-5.1   Method 5: Use Docker container    DeepStream docker containers are available on NGC. See the Docker Containers section to learn about developing and deploying DeepStream using docker containers.\nRun deepstream-app (the reference application)      Navigate to the samples directory on the development kit.\n  Enter the following command to run the reference application:\n$ deepstream-app -c \u0026lt;path_to_config_file\u0026gt; Where \u0026lt;path_to_config_file\u0026gt; is the pathname of one of the reference application’s configuration files, found in configs/deepstream-app/. See Package Contents for a list of the available files.\n Note: You can find sample configuration files under /opt/nvidia/deepstream/deepstream-5.1/samples directory. Enter this command to see application usage: $ deepstream-app --help To save TensorRT Engine/Plan file, run the following command: $ sudo deepstream-app -c \u0026lt;path_to_config_file\u0026gt;\n   To show labels in 2D Tiled display view, expand the source of interest with mouse left-click on the source. To return to the tiled display, right-click anywhere in the window.\n  Keyboard selection of source is also supported. On the console where application is running, press the z key followed by the desired row index (0 to 9), then the column index (0 to 9) to expand the source. To restore 2D Tiled display view, press z again.\n  Boost the clocks    After you have installed DeepStream SDK, run these commands on the Jetson device to boost the clocks:\n$ sudo nvpmodel -m 0 $ sudo jetson_clocks Run precompiled sample applications      Navigate to the chosen application directory inside sources/apps/sample_apps.\n  Follow the directory’s README file to run the application.\n Note: If the application encounters errors and cannot create Gst elements, remove the GStreamer cache, then try again. To remove the GStreamer cache, enter this command: $ rm ${HOME}/.cache/gstreamer-1.0/registry.aarch64.bin When the application is run for a model which does not have an existing engine file, it may take up to a few minutes (depending on the platform and the model) for the file generation and the application launch. For later runs, these generated engine files can be reused for faster loading.\n   DeepStream application development in Python    Python bindings are included in the DeepStream 5.1 SDK and the sample applications are available here.\nAll steps are also available here.\nPrerequisites     Ubuntu 18.04 DeepStream SDK 5.1 or later Python 3.6 Gst Python v1.14.5. If Gst python installation is missing on Jetson, install using the following commands:  $ sudo apt-get install python-gi-dev $ export GST_LIBS=\u0026quot;-lgstreamer-1.0 -lgobject-2.0 -lglib-2.0\u0026quot; $ export GST_CFLAGS=\u0026quot;-pthread -I/usr/include/gstreamer-1.0 -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include\u0026quot; $ git clone https://github.com/GStreamer/gst-python.git $ cd gst-python $ git checkout 1a8f48a $ ./autogen.sh PYTHON=python3 $ ./configure PYTHON=python3 $ make $ sudo make install Running Sample Applications      Clone the deepstream_python_apps repo under \u0026lt;DeepStream 5.1 ROOT\u0026gt;/sources\n$ git clone https://github.com/NVIDIA-AI-IOT/deepstream_python_apps   This will create the following directory:\n$ \u0026lt;DeepStream 5.1 ROOT\u0026gt;/sources/deepstream_python_apps   The Python apps are under the apps directory. Go into each app directory and follow instructions in the README.\n Note: The app configuration files contain relative paths for models.\n   "},{"id":8,"href":"/documentation/categories/","title":"Categories","parent":"Documentation","content":""},{"id":9,"href":"/documentation/diagrams/","title":"Diagrams","parent":"Documentation","content":""},{"id":10,"href":"/documentation/","title":"Documentation","parent":"","content":""},{"id":11,"href":"/documentation/modules/","title":"Modules","parent":"Documentation","content":""},{"id":12,"href":"/documentation/tags/","title":"Tags","parent":"Documentation","content":""},{"id":13,"href":"/documentation/tools/","title":"Tools","parent":"Documentation","content":""}]